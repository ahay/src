\published{Geophysics, 79, no. 5, V179-V189, (2014)}

\title{Iterative deblending of simultaneous-source seismic data using seislet-domain shaping regularization}
\renewcommand{\thefootnote}{\fnsymbol{footnote}}
%\author{Yangkang Chen\footnotemark[1], Sergey Fomel\footnotemark[1] and Jingwei Hu\footnotemark[1]}
\author{Yangkang Chen, Sergey Fomel, and Jingwei Hu}
% width=0.2500\textwidth, height=0.2800\textwidth good
% width=0.2500\textwidth, height=0.2800\textwidth
% width=0.2300\textwidth, height=0.2700\textwidth

\ms{GEO-2013-449}

\address{
Bureau of Economic Geology \\
John A. and Katherine G. Jackson School of Geosciences \\
The University of Texas at Austin \\
University Station, Box X \\
Austin, TX 78713-8924 \\
}

\lefthead{Chen et al.}
\righthead{Deblending using shaping regularization}
\footer{TCCS-7}
\maketitle

\begin{abstract}
We introduce a novel iterative estimation scheme for separation of blended seismic data from simultaneous sources. The scheme is based on an augmented estimation problem, which can be solved by  iteratively constraining the deblended data using shaping regularization in the seislet domain. We formulate the forward modeling operator in the common receiver domain, where two sources are assumed to be blended using a random time-shift dithering approach. The nonlinear shaping-regularization framework offers some freedom in designing a shaping operator to constrain the model in an underdetermined inverse problem. We design the backward operator and the shaping operator for the shaping regularization framework. The backward operator can be optimally chosen as a half of the identity operator in the two-source case, and the shaping operator can be chosen as coherency-promoting operator. Three numerically blended synthetic datasets and one numerically blended field dataset demonstrate the high-performance deblending effect of the proposed iterative framework. Compared with alternative $f-k$ domain thresholding and $f-x$ predictive filtering, seislet-domain soft thresholding exhibits the most robust behavior.
\end{abstract}

\section{Introduction}
\inputdir{synth}
%The technique of simultaneous source means firing more than one shots at nearly the same time.  The novel technique can reduce the acquisition time and at the same time increase the spatial sampling \cite[]{berk}. Because of its economic benefit and technical challenge, it has attracted the attention of both the industry and research field. In conventional acquistion, shot intervals are large enough so that the crosstalk between successive shots can be left out. However, in simultaneous acquisition, the interference is intense, which requires new processing techniques to remove it out. 

%After separation, the conventional precessing procedures like migration can take place just like conventional acquision methods. \cite{rtm} develop quasi-linear inversion and linear inversion to implement least-squares migration with the reverse time migration method and the blended source processing technique to increase computation effiency. \cite{fwi} proved that full waveform inversion after a crude deblending of the distance separated simultaneous sweeping dataset leads to a result very similar to the one obtained from the single vibrator, single receiver dataset. \cite{mwi} use the global correlation between observed and modelled data as an alternative objective function to apply the multi-source waveform inversion to marine streamer data. \cite{sfi} by changing the coding sequence perodically in simultaneous source full waveform inversion mitigates the effect of leaving crosstalk noise in the final result.

%Wide azimuth acquisition (WAA) can improve the illumination of subsalt structures, which helps in turn improve the quality of seismic imaging \cite[]{waz}. However, WAA suffers from the low efficiency problem, resulting from the large temporal shooting interval between two consecutive shots \cite[]{beasley1,beasley2,berk}. The large shooting interval ensures that no interference exists between adjacent shots. An alternative way to avoid interference is by increasing the spatial shooting interval, which results in serious spatial aliasing problems. 

The simultaneous-source technique aims at removing the limitation of no interference between adjacent shots by allowing more than one source to be shot simultaneously. Thus it can reduce the acquisition period and increase spatial sampling \cite[]{berk}. Because of its economic benefits and technical challenges, this technique has attracted significant attention of researchers in both industry and academia \cite[]{moore2008,mahdad2011,abma,mediandeblend,deblendinv}. The biggest issue involved in simultaneous-source processing is an intense crosstalk noise between adjacent shots, which poses a challenge for conventional processing. One way to deal with this issue is to use a first-separate and second-process strategy, which is also known as \emph{deblending} \cite[]{pana1}. The other way is by direct imaging and waveform inversion \cite[]{berkhout2012,choi2012,plessix2012,guitton2012,zhiguang2014}. In this paper, we focus on the deblending approach.

Different filtering and inversion methods have been applied previously to deblend seismic data. Filtering methods utilize the property that the coherency of the simultaneous-source data varies in different domains. Therefore, one can get unblended data by filtering out randomly distributed blending noise in some transform domains, where one source record is coherent and the others are not \cite[]{gary,iter,mediandeblend}. Inversion methods treat the separation problem as an estimation problem, which aims at estimating the desired unknown unblended data. Because of the ill-posed nature of such estimation problems, a regularization term is usually required \cite[]{pana2}. The regularization term can be chosen as a sparsity promotion in a sparsifying transformed domain \cite[]{abma2010}. \cite{roald} proposed to distribute all energy in the %simultaneous 
shot records by reconstructing individual shot records at their respective locations. \cite{mahdad2011} introduced an iterative estimation and subtraction scheme that combines the properties of filtering and inversion methods and exploits the fact that the characteristics of the blending noise differ in different domains. One choice is to transform seismic data from the common-shot domain to common-receiver, common-offset or common-midpoint domain. \cite{proj} proposed a separation technique called the alternating projection method, and demonstrated it to be robust in the presence of aliasing. 
%However, most of the published methods will either cause heavy signal leakage or cause large iterative computation. New efficient and robust deblending scheme is still demanded.

In this paper, we propose a novel iterative estimation scheme for the separation of blended seismic data. We construct an augmented estimation problem, then use shaping regularization \cite[]{fomel2,fomel3} to constrain the characteristics of the model during the iteration process for obtaining a suitable estimation result. %In our method, two equations are solved simultaneously, which helps improve efficiency and accuracy of conventional independent processing. 
We adopt seislet-domain \cite[]{seislet} soft thresholding as a robust shaping operator to remove crosstalk noise and at the same time to preserve useful components of seismic data. Shaping regularization maps each model into a more admissible model at each iteration and allows us to solve the deblending problem with a small number of iterations. 

This paper is organized as follows: we first present a formulation of numerical blending using an augmented block-matrix equation. We then incorporate shaping regularization to solve the forward equation iteratively and discuss the selection of the backward operator and shaping operator involved in the shaping-regularization iterative framework. Finally, we test the proposed iterative framework on three numerically blended synthetic datasets and one numerically blended field dataset and compare three different choices of the shaping operator: $f-k$ domain thresholding, $f-x$ predictive filtering, and seislet domain thresholding. 
 
\section{Deblending using shaping regularization}
%\subsection{Numerical blending and iterative deblending}
\subsection{Numerical blending}
\inputdir{synth}
%It has been recognized that by transforming the seismic data from common shot domain to common receiver domain, we can use the incoherency characteristics of one source to separate the blended record. 
We assume that the seismic record is blended using two independent sources, which correspond to two shooting vessels in the ocean bottom nodes (OBN) acquisition \cite[]{obn}. Here, one source means a collection of shots from one shooting vessel. The
two sources shoot pseudosynchronously, which means that each shot in one source has a random time dithering compared with the corresponding shot in another source.  By precisely picking the shooting time of each shot of one source at the long seismic record on the node, we can get one common receiver gather. Using the second source, we get another gather.
%Blended record in the common receiver domain is coherent for one source and incoherent for another, because each trace of the common receiver gather corresponds to one shot for one source.
% and the shooting time delay between the two pseudo-synchronized sources are randomly distributed, which means there is a random dithering between each pair of two corresponding traces of the two gathers. 
Thus, the forward problem can be formulated as follows:
%\begin{eqnarray}
%\begin{align}
%\label{eq:inv}
%\mathbf{d}&=\mathbf{s}_1+\mathbf{T}\mathbf{s}_2 \\ \nonumber
%\mathbf{T}^{-1}\mathbf{d}&=\mathbf{T}^{-1}\mathbf{s}_1+\mathbf{s}_2.
%\end{align}
%\end{eqnarray}
\begin{equation}
\label{eq:inv}
\mathbf{d}=\mathbf{d}_1+\mathbf{Td}_2.
\end{equation}
Here, $\mathbf{d}_1$ and $\mathbf{d}_2$ denote the seismic records to be separated out, $\mathbf{d}$ is the blended data, and $\mathbf{T}$ denotes the dithering operator. Note that we perform the processing in the common-receiver domain, because each blended record in this domain is coherent for one source and incoherent for another \cite[]{gary}. In this case, $\mathbf{d}$ is usually referred to as the pseudodeblended data \cite[]{mahdad2011}, which means picking traces from the original blended field record according to the shooting time of one source to form a common receiver gather with one source coherent and the other one incoherent. 
We propose to augment equation \ref{eq:inv} with another equation through applying the inverse dithering operator $\mathbf{T}^{-1}$:
\begin{equation}
\label{eq:inv1}
\mathbf{T}^{-1}\mathbf{d}=\mathbf{T}^{-1}\mathbf{d}_1+\mathbf{d}_2.
\end{equation}
By combining equations \ref{eq:inv} and \ref{eq:inv1}, we formulate an augmented estimation problem:
%\begin{equation}
%\label{eq:inv1}
%\left[\begin{array}{rr}
%\mathbf{d}\\
%\mathbf{T}^{-1}\mathbf{d}
%\end{array}\right]=
%\left[\begin{array}{rr}
%\mathbf{I} 	& \mathbf{T}\\
%\mathbf{T}^{-1} & \mathbf{I}
%\end{array}\right]
%\left[\begin{array}{rr}
%\mathbf{r}_1\\
%\mathbf{r}_2
%\end{array}\right].
%\end{equation}
%Let $\mathbf{m}$ denote the right part of the right hand side of the above equation, F denote the left part of the right hand side of the above equation and $\mathbf{\tilde{d}}$ denote the left hand side of the above equation. Then, 
%Equation \ref{eq:inv} can be expressed as a linear estimation problem:
\begin{equation}
\label{eq:esti}
\mathbf{Fm}=\mathbf{\tilde{d}},
\end{equation}
where
\begin{eqnarray}
\label{eq:note}
\mathbf{\tilde{d}}=
\left[\begin{array}{cc}
\mathbf{d}\\
\mathbf{T}^{-1}\mathbf{d}
\end{array}\right],
\quad
\mathbf{F}=
\left[\begin{array}{cc}
\mathbf{I} 	& \mathbf{T}\\
\mathbf{T}^{-1} & \mathbf{I}
\end{array}\right],
\quad
\mathbf{m}=
\left[\begin{array}{cc}
\mathbf{d}_1\\
\mathbf{d}_2
\end{array}\right],
\end{eqnarray}
and $\mathbf{I}$ is the identity operator.
%An estimate of the model $\mathbf{m}$ can be obtained by a simple iteration as follows:
%\begin{equation}
%\label{eq:iter1}
%\mathbf{m}_{n+1}=\mathbf{m}_n+\mathbf{B}\mathbf{\tilde{d}}-\mathbf{BFm}_n,
%=\mathbf{B\tilde{d}}+(\mathbf{I}-\mathbf{BF})\mathbf{m}_n,
%\end{equation}
%where $\mathbf{B}$ is the backward operator that provides an inverse mapping from data space to model space. 

We choose to solve equation \ref{eq:esti} rather than equation \ref{eq:inv} because equation \ref{eq:esti} is a more convenient form to use in the following derivations.

\subsection{Shaping regularization}
%If $\mathbf{B}$ is taken as the adjoint of $\mathbf{F}$, iteration \ref{eq:iter1} is known as the \emph{Landweber iteration} \cite[]{landweber}. The Landweber iteration solves the system of normal equations and converges to the least-squares estimate of $\mathbf{m}$:
%\begin{equation}
%\label{eq:least}
%\min_{\mathbf{m}} \parallel \mathbf{Fm}-\mathbf{\tilde{d}} \parallel_2^2,
%\end{equation}
%where $\parallel \cdot \parallel_2^2$ denotes the squared $L_2$ norm of a function. The least-squares optimization problem \ref{eq:least} are usually regularized by adding a regularization term:
%a sparsity constraint:
%\begin{equation}
%\label{eq:leastreg}
%\min_{\mathbf{m}} \parallel \mathbf{Fm-\tilde{d}} \parallel_2^2 +\mathbf{R}(\mathbf{m}),%\epsilon\parallel \mathbf{m} \parallel_p,
%\end{equation}
%where $\mathbf{R}(\cdot)$ is a regularization operator.
%where $\epsilon$ is regularization scaling and $\parallel \cdot \parallel_p$ is an $L_p$ (typically $L_1$) norm of a function, which promotes sparsity \cite[]{microspa}.
%Alternatively, with a shaping operator $\mathbf{S}$ \cite[]{fomel3}, iteration \ref{eq:iter1} can be modifed to the following equation: 
The unknown $\mathbf{m}$ in equation \ref{eq:esti} can be recovered iteratively using shaping regularization:
\begin{equation}
\label{eq:iter2}
\mathbf{m}_{n+1}=\mathbf{S}[\mathbf{m}_n+\mathbf{B}(\mathbf{\tilde{d}}-\mathbf{Fm}_n)],
\end{equation}
where operator $\mathbf{S}$ shapes the estimated model into the space of admissible models at each iteration \cite[]{fomel2,fomel3} and $\mathbf{B}$ is the backward operator that provides an inverse mapping from data space to model space.
\cite{daubechies} prove that, if $\mathbf{S}$ is a nonlinear thresholding operator \cite[]{donoho}, $\mathbf{B}=\mathbf{F}^T$ where $\mathbf{F}^T$ is the adjoint operator of $\mathbf{F}$, iteration \ref{eq:iter2} converges to the solution of equation \ref{eq:leastreg} with $L_1$ regularization term:
\begin{equation}
\label{eq:leastreg}
\min_{\mathbf{m}} \parallel \mathbf{Fm-\tilde{d}} \parallel_2^2 +\mu\parallel\mathbf{A}^{-1}\mathbf{m}\parallel_1,%\epsilon\parallel \mathbf{m} \parallel_p,
\end{equation}
where $\mu$ is the threshold and $\mathbf{A}^{-1}$ denotes a sparsity-promoting transform. 
A better choice for $\mathbf{B}$ is the pseudoinverse of $\mathbf{F}$: $\mathbf{B}=(\mathbf{F}^T\mathbf{F})^{-1}\mathbf{F}^T$ \cite[]{daubechies2008}.
%Choosing an appropriate $\mathbf{W}$, $\mathbf{B}$ can has the following form:
%\begin{equation}
%\label{eq:back}
%\mathbf{B}=\lambda\mathbf{I},
%\end{equation}
%where $\lambda$ is a scaling coefficient and $\mathbf{I}$ is an identity operator.
%\subsection{Checking convergence and stopping criterion}
\subsection{Performance evaluation and convergence rate}
Combining equations \ref{eq:esti}, \ref{eq:note} and \ref{eq:iter2}, we get: 
\begin{equation}
\label{eq:main}
\left[\begin{array}{cc}
\mathbf{d}_1\\
\mathbf{d}_2
\end{array}\right]_{n+1}=\mathbf{S}
\left[
\left[\begin{array}{cc}
\mathbf{d}_1\\
\mathbf{d}_2
\end{array}\right]_n+
\mathbf{B}\left[\left[\begin{array}{cc}
\mathbf{d}\\
\mathbf{T}^{-1}\mathbf{d}
\end{array}\right]-\left[\begin{array}{cc}
\mathbf{I}	& \mathbf{T}\\
\mathbf{T}^{-1} & \mathbf{I}
\end{array}\right]
\left[\begin{array}{cc}
\mathbf{d}_1\\
\mathbf{d}_2
\end{array}\right]_n
\right]\right],
\end{equation}
where $\mathbf{S}$ is a block operator that takes the form
%\old{$\left[\begin{array}{cc}
%\mathbf{S}_1	& 0\\
%0 & \mathbf{S}_2
%\end{array}\right]$}
$[\mathbf{S}_1\quad \mathbf{0};\mathbf{0}\quad\mathbf{S}_2]$, and $\mathbf{S}_1$ and $\mathbf{S}_2$ correspond to the shaping operators for $\mathbf{d}_1$ and $\mathbf{d}_2$, respectively. Using equation \ref{eq:main} and performing appropriate iterations, we aim to get an estimate of unblended seismic data.

To test the convergence performance and accuracy of iteration \ref{eq:main}, we use the following measure \cite[]{hennenfent2006}:
\begin{equation}
\label{eq:diff}
SNR_{i,n}=10\log_{10}\frac{\Arrowvert \mathbf{d}_i \Arrowvert_2^2}{\Arrowvert \mathbf{d}_i-\mathbf{d}_{i,n}\Arrowvert_2^2},
\end{equation}
where $SNR_{i,n}$ stands for signal-to-noise ratio of $i$th source after $n$th iteration, $\mathbf{d}_{i,n}$ denotes the estimated model of $i$th source after $n$ iterations, $\mathbf{d}_i$ denotes the true model for $i$th source and $\parallel \cdot \parallel_2^2$ denotes the squared $L_2$ norm of a function.

%When $SNR_{i,n}$ is bigger than a predefined value $\epsilon$, or the iteration number $n$ is bigger than a predifined maximum iteration number $N_{max}$, iteration \ref{eq:main} stops.

\section{Backward operator}
In equation \ref{eq:iter2}, $\mathbf{B}$ is an approximate inverse of $\mathbf{F}$. 
%To get a $\mathbf{B}$ as similar to the pseudo-inverse of $\mathbf{F}$ as possible is crucial to the convergence and accuracy to iteration \ref{eq:iter2} \cite[]{daubechies2008}. 
Recall that the dithering operator applies a time-domain random time shift to the input seismic data. Taken in the frequency domain, the dithering operator takes the following form: 
\begin{equation}
\label{eq:ditherf}
\mathbf{T} = \mathbf{\mathcal{F}}^{-1}\mathbf{P}\mathbf{\mathcal{F}},
\end{equation}
where $\mathbf{\mathcal{F}}$ and $\mathbf{\mathcal{F}}^{-1}$ are forward and inverse Fourier transforms, respectively, and $\mathbf{P}$ is a $N\times N$ diagonal block phase-shift operator given by
\begin{equation}
\label{eq:phaseshift}
\mathbf{P}=diag(\mathbf{P}_1, \mathbf{P}_2, \mathbf{P}_3, \cdots, \mathbf{P}_N),
\end{equation}
%\begin{equation}
%\label{eq:phaseshift}
%\mathbf{P} = \left[\begin{array}{cccccccc} 
%\mathbf{P}_1 & 	       & 	  & 	     &		 &	\\
%	   &\mathbf{P}_2 & 	  &	     &		 &	\\
%	   &           &\mathbf{P}_3&	     &		 &	\\
%	   &  	       &          &\mathbf{\ddots}&	         & 	\\
%	   &	       &	  &	     & \mathbf{\ddots} & \\
%	   &	       &	  &	     &		 & \mathbf{P}_N 
%\end{array}\right]_{N\times N},
%\end{equation}
where 
$\mathbf{P}_n$ denotes the individual phase shift operator for $n$th trace and can be expressed as a $M\times M$ diagonal matrix:
\begin{equation}
\label{eq:phaseshift1}
\mathbf{P}_n = diag(\overbrace{1,1,1, \cdots, 1}^{M})*\exp(-i\omega\delta t_n).
\end{equation}
%\wen{
%\begin{equation}
%\label{eq:phaseshift1}
%\mathbf{P}_n = \left[\begin{array}{cccccccc} 
%e^{-i\omega\delta t_n} & 	       & 	  & 	     &		 &	\\
%	   &e^{-i\omega\delta t_n} & 	  &	     &		 &	\\
%	   &           &e^{-i\omega\delta t_n}&	     &		 &	\\
%	   &  	       &          &\mathbf{\ddots}&	         & 	\\
%	   &	       &	  &	     & \mathbf{\ddots} & \\
%	   &	       &	  &	     &		 & e^{-i\omega\delta t_n}
%\end{array}\right]_{M\times M}.
%\end{equation}
Here, $w$ denotes the angular frequency, $\delta t_n$ denotes the random dithering time of $n$th trace, and $M$ and $N$ in equations \ref{eq:phaseshift} and \ref{eq:phaseshift1} denote the number of temporal samples and number of traces, respectively. $diag(\cdot)$ denotes a diagonal matrix. 

Considering that the Fourier operator (with symmetric normalization) and the phase shift operator are both unitary, which means $\mathbf{\mathcal{F}}^{-1}=\mathbf{\mathcal{F}}^{T}$ and $\mathbf{P}^{-1}=\mathbf{P}^T$, it is easy to see that 
\begin{equation}
\label{eq:unitary}
\begin{split}
\mathbf{T}^T &=(\mathbf{\mathcal{F}}^{-1}\mathbf{P}\mathbf{\mathcal{F}})^T =\mathbf{\mathcal{F}}^T\mathbf{\mathbf{P}}^T\mathbf{\mathcal{F}} =(\mathbf{\mathcal{F}}^{-1}\mathbf{P}\mathbf{\mathcal{F}})^{-1} =\mathbf{T}^{-1}.
\end{split}
\end{equation}
Thus, we conclude that the dithering operator is also a unitary operator.\\
Furthermore we notice that
\begin{equation}
\label{eq:back2}
\mathbf{F}^T=
\left[\begin{array}{cc}
\mathbf{I} 	& \mathbf{T}\\
\mathbf{T}^{-1} & \mathbf{I}
\end{array}\right]^T=
\left[\begin{array}{cc}
\mathbf{I} 	& \mathbf{T}^{-T}\\
\mathbf{T}^{T} & \mathbf{I}
\end{array}\right]=
\left[\begin{array}{cc}
\mathbf{I} 	& \mathbf{T}\\
\mathbf{T}^{-1} & \mathbf{I}
\end{array}\right]=
\mathbf{F}, \nonumber 
\end{equation}
and:
\begin{equation}
\label{eq:back3}
\mathbf{F}^T\mathbf{F}=\left[\begin{array}{cc}
\mathbf{I} 	& \mathbf{T}\\
\mathbf{T}^{-1} & \mathbf{I}
\end{array}\right]
\left[\begin{array}{cc}
\mathbf{I} 	& \mathbf{T}\\
\mathbf{T}^{-1} & \mathbf{I}
\end{array}\right]=
2\left[\begin{array}{cc}
\mathbf{I} 	& \mathbf{T}\\
\mathbf{T}^{-1} & \mathbf{I}
\end{array}\right]=
2\mathbf{F}.
\end{equation}

The least-squares solution of equation \ref{eq:esti} is therefore:
\begin{equation}
\label{eq:solu}
\mathbf{\hat{m}}=(\mathbf{F}^T\mathbf{F})^{-1}\mathbf{F}^{T}\mathbf{\tilde{d}}=\frac{1}{2}\mathbf{F}^{-1}\mathbf{F}^T\mathbf{\tilde{d}}=\frac{1}{2}\mathbf{\tilde{d}}.
\end{equation}

According to equation \ref{eq:solu}, an appropriate choice for $\mathbf{B}$ is simply 
%$\mathbf{B}=\frac{1}{2}\left[\begin{array}{cc}
%\mathbf{I}	& 0\\
%0 & \mathbf{I}
%\end{array}\right]$. 
$\mathbf{B}=\frac{1}{2}[\mathbf{I}\quad\mathbf{0};\mathbf{0}\quad\mathbf{I}]$. This form of the derived backward operator is also referred to as scaled pseudodeblending \cite[]{arazthesis}.

The dithering operator is unitary only if the time-shift range is small and so the constructive summation of the useful components (events) between different traces can be ignored. Even if this condition isn't fully met, we can use the concept of interference to generalize the meaning of the dithering operator $\mathbf{T}$. Although, in this case, the backward operator might not be most appropriately chosen as half of the identity operator, we can still use it as an approximation.

%Equation \ref{eq:back} gives a variable-scaling update of data misfit during the iteration, if $\lambda=1$, we use the data misfit of the previous iterated model as the update for the current model, but we can reduce the update level by just use the half ($\lambda=0.5$) of the data misfit or another fraction ($\lambda$) of the data misfit as the update, which can get a variable convergence rate and accuracy level.
%Introducing scaling of $\mathbf{F}$ by a matrix $\mathbf{W}$ in equation \ref{eq:esti} and let $\mathbf{\tilde{F}=WF}$, we get:
%Substitute $\mathbf{\tilde{F}}$ and $\mathbf{\tilde{F}^T}$  to $\mathbf{F}$  and $\mathbf{B}$ respectively in iteration \ref{eq:iter1}, we get:
%\begin{equation}
%\label{eq:iter1}
%\mathbf{m}_{n+1}=\mathbf{m}_n+\mathbf{F^T\tilde{d}}+(\mathbf{I}-\mathbf{BF})\mathbf{m}_n,
%\end{equation}
%In linear notation, $m$ can be obtained by solving the least-squares problem:
%\begin{equation}
%\label{eq:least}
%min \parallel \mathbf{Fm}-\mathbf{\tilde{d}} \parallel_2^2,
%\end{equation}
%where $\parallel \cdot \parallel$ denotes the squared L-2 norm of a function.
%Introducing scaling of $\mathbf{F}$ by a matrix $\mathbf{W}$ in equation \ref{eq:least}, we 
%The standard regularization form for equation \ref{eq:esti} aims to mimimize the least-square norm of the compound vector$[\mathbf{Fm}-\mathbf{\tilde{d}} \quad \epsilon \mathbf{Rm}]^T$, where $\epsilon$ is a scalar scaling parameter and $\mathbf{R}$ is the Tikhonov regularization operator \cite[]{tik}. The formal solution, denoted by $\mathbf{\hat{m}}$, is given by:
%\begin{equation}
%\label{eq:model}
%\mathbf{\hat{m}}=(\mathbf{F}^T\mathbf{F}+\epsilon^2\mathbf{R}^T\mathbf{R})^{-1}\mathbf{F}^T\mathbf{\tilde{d}},
%\end{equation}
%where $\mathbf{F}^T$ denotes the adjoint operator of $\mathbf{F}$. \cite{fomel2} modified equation \ref{eq:model} to:
%\begin{equation}
%\label{eq:model2}
%\mathbf{\hat{m}}=[\mathbf{I}+\mathbf{S}(\mathbf{BF}-\mathbf{I})]^{-1}\mathbf{SB}\mathbf{\tilde{d}},
%\end{equation}
%where $\mathbf{S}$ is a shaping operator defined as $\mathbf{S}=(\mathbf{I}+\epsilon^2\mathbf{R}^T\mathbf{R})^{-1}$, and $\mathbf{B}$ denotes the backward operator of $\mathbf{F}$.

\section{Shaping operator}
The shaping operator $\mathbf{S}$ in equation \ref{eq:iter2} can be chosen as a coherency-promoting operator, which serves as a flexible constraint on the estimated model.
%\subsection{Coherency-promoting shaping operator}
Any coherency-promoting tool such as $f-x$ predictive filtering \cite[]{canales1984,sacchi2000,galbraith2012,yangkang2014} or median filter \cite[]{liuyang2009tvmf,mediandeblend,yike2013} can be utilized to preserve the coherent useful subsurface reflection and at the same time to remove incoherent blending noise. 
%A coherency promoting shaping operator can be noted as $\mathbf{S}_i=\mathbf{\mathcal{C}_{\mathbf{\lambda}_i}}$, 

%\begin{equation}
%\label{eq:coherence}
%\mathbf{S}_i=\mathbf{\mathcal{C}}_{\mathbf{\lambda}_i},
%\end{equation}
%where $i$ denotes the $i$th source, $\mathbf{\mathcal{C}}$ denotes a specific coherency promoting filter and $\mathbf{\lambda}_i$ corresponds to the input parameter vector for filter $\mathbf{\mathcal{C}}$.

%\subsection{Sparsity-promoting shaping operator}
Another approach to promote coherency is to promote sparseness in an appropriate transform domain. To enforce sparsity, a transform domain thresholding operation can also be chosen as the shaping operator as long as the data in the transformed domain is sparse \cite[]{mallat2009,candes2010}. Instead of a thresholding operator, we can also use a mask operator to compress the transformed domain \cite[]{mostafa2010,liuyang2012}. A sparsity-promoting shaping operator can be defined as:
\begin{align}
\label{eq:sparse1}
\mathbf{S}_i =\mathbf{A}\mathbf{\mathcal{T}}_{\mathbf{\gamma}_i}[\mathbf{A}^{-1}], 
\end{align}
where $i$ denotes the $i$th source, $\mathbf{A}^{-1}$ and $\mathbf{A}$ are forward and inverse sparsity-promoting transforms and $\mathbf{\mathcal{T}}_{\gamma_i}$ corresponds to a mask operator or thresholding operator with an input parameter $\gamma_i$ in the transformed domain.

Mask operator can be chosen to preserve small-scale components and remove large-scale components. It takes the following form:
\begin{equation}
\label{eq:mask}
%\mathbf{\mathcal{T}}_{\gamma_i} (\mathbf{x}) = 
\mathbf{\mathcal{M}}_{\gamma_i}(v(\mathbf{x})) = \left\{ \begin{array}{ll}
v(\mathbf{x}) & \text{for}\quad  s(\mathbf{x}) < \gamma_i  \\
0	      & \text{for}\quad  s(\mathbf{x}) \ge \gamma_i
\end{array}\right.,
\end{equation}
where $\mathbf{x}$ is a position vector in the transformed domain, $v(\mathbf{x})$ denotes the amplitude value of point $\mathbf{x}$, $s(\mathbf{x})$ denotes the scale of point $\mathbf{x}$ and $\mathbf{\mathcal{M}}_{\gamma_i}$ corresponds to the mask operator with a scale limitation $\gamma_i$. When the sparsity-promoting transform is the Fourier transform, the scale defined in the mask operator shown in equation \ref{eq:mask} corresponds to the frequency and wavenumber band.

Thresholding operators can be divided into two types: soft and hard. Soft thresholding or shrinkage aims to remove data whose value is smaller than a certain level and subtract the other data values by this level \cite[]{donoho1995}. Hard thresholding simply removes data with small values. A soft thresholding operator takes the following form:
%Figures \ref{fig:sletthr} and \ref{fig:sletcut} show the seislet-domain after applying soft thresholding and mask operator.
\begin{equation}
\label{eq:soft}
%\mathbf{\mathcal{T}}_{\gamma_i} (\mathbf{x}) =
\mathbf{\mathcal{S}}_{\gamma_i}(v(\mathbf{x})) = \left\{ \begin{array}{ll}
v(\mathbf{x})-\gamma_i \frac{v(\mathbf{x})}{|v(\mathbf{x})|} & \text{for}\quad  |v(\mathbf{x})| > \gamma_i  \\
0			      & \text{for}\quad  |v(\mathbf{x})| \le \gamma_i
\end{array}\right.,
\end{equation}
where $\mathbf{\mathcal{S}}_{\gamma_i}$ corresponds to the soft thresholding operator with a threshold value $\gamma_i$.

Similarly, a hard thresholding operator takes the form:
\begin{equation}
\label{eq:hard}
%\mathbf{\mathcal{T}}_{\gamma_i} (\mathbf{x}) =
\mathbf{\mathcal{H}}_{\gamma_i}(v(\mathbf{x})) = \left\{ \begin{array}{ll}
v(\mathbf{x})  & \text{for}\quad  |v(\mathbf{x})| > \gamma_i  \\
0			      & \text{for}\quad |v(\mathbf{x})|  \le \gamma_i
\end{array}\right.,
\end{equation}
where $\mathbf{\mathcal{H}}_{\gamma_i}$ corresponds to the hard thresholding operator with a threshold value $\gamma_i$.

%What is worth to be mentioned is that soft thresholding \ref{eq:soft} corresponds to an $L_1$ norm regularization in equation \ref{eq:leastreg} with $\mathbf{R}(\mathbf{m})$ taken as $\mathbf{\gamma}\Arrowvert \mathbf{A}^{-1}\mathbf{m}\Arrowvert_1$ ($\mathbf{\gamma}=[\gamma_1,\gamma_2]$), and hard thresholding \ref{eq:hard} corresponds to an $L_0$ norm regularization in equation \ref{eq:leastreg} with $\mathbf{R}(\mathbf{m})$ taken as $\frac{1}{2}\mathbf{<\gamma,\gamma>}\Arrowvert \mathbf{A}^{-1}\mathbf{m}\Arrowvert_0$ ($\mathbf{\gamma}=[\gamma_1,\gamma_2]$) \cite[]{daubechies,wright2009,pengliang2013}.


The mask operator can be more efficient because it is linear and requires only the scale coefficient below which data values are preserved. The thresholding operator needs to compare the amplitude value of each transformed domain point with a predefined coefficient. However, the mask operator is more difficult to design when the signal and noise coefficients are both spread across the transformed domain. Therefore, in the case of deblending, we prefer to use the thresholding operator rather than the mask operator. The selection criteria of $\gamma_i$ in the above definitions of thresholding operators (both soft and hard) leads to different kinds of thresholding strategies, which may result in different thresholding performances (convergence rate and quality) \cite[]{pengliang2013}. Some of the common iterative thresholding strategies are constant-value thresholding, linear-decreasing thresholding, exponential-decreasing thresholding, etc. \cite[]{jianjun2010}.  In our paper, we use percentile thresholding \cite[]{dian2008,pengliang20121}, which is convenient to implement and helps accelerate the convergence \cite[]{pengliang20121}. %Comparisons of those common thresholding strategies can be found in \cite{pengliang2013,jianjun2010}, and is beyond the scope of this paper.} 
% as the shaping operator 

\subsection{Comparison of sparsity-promoting transforms}
The best-known sparsity-promoting transforms are the Fourier %\cite[]{chandrasekharan1949} 
and wavelet transform. 
%\cite[]{akansu2010}.  
\cite{seislet} proposed a sparsity-promoting transform called \emph{seislet} transform. The specific adaptation for seismic data makes the seislet transform appealing to seismic data processing. In the seislet domain, useful events and blending noise reside at different scales and the useful signal tends to form a more compact region\. We provide a brief review of the seislet transform in Appendix A.

In order to illustrate the comparative sparseness of different transforms, we first create a simple synthetic data (Figure \ref{fig:test1}). Figure \ref{fig:ft,wlet,slet0,sigcoef} shows different transformed domains for the data. Figure \ref{fig:sigcoef} shows a comparison between the decay of sorted coefficients in the 2-D Fourier transform, 2-D wavelet transform, and 2-D seislet transform. The 2-D Fourier transform in this case means the $f-k$ transform. The 2-D wavelet transform means implementing the 1-D wavelet transform along the temporal direction first and along the spatial direction second. The 2-D seislet transform means implementing the seislet transform along the spatial direction first and 1-D seislet transform along the temporal direction second. Our experiments show that the seislet coefficients decay significantly faster than coefficients of the other two transforms, which indicates a more compact structure of the seislet domain. The shaping operation is thus preferably chosen as the thresholding or mask operation in the seislet domain.

%Figure \ref{fig:slet,sletthr} shows what the seislet domain looks like for the blended seismic data shown in Figure \ref{fig:blendedsyn}. 
%Figure \ref{fig:slet} shows the seislet domain of Figure \ref{fig:blendedsyn}, Figure \ref{fig:sletthr} shows the thresholded seislet domain. Obviously much blending noise has been removed out after applying soft shresholding. 

\inputdir{hyper}
\plot{test1}{width=0.7\textwidth}{A synthetic seismic profile.}
\multiplot{4}{ft,wlet,slet0,sigcoef}{width=0.45\textwidth,height=0.35\textwidth}{Comparison among different sparsity-promoting transforms. (a) 2-D Fourier transform domain. (b) 2-D Wavelet transform domain. (c) 2-D Seislet transform domain. (d) Coefficients decreasing diagram.}



\section{Examples}
In this section, in order to test the effectiveness of the proposed iterative framework defined in equation \ref{eq:iter2}, we create three numerically blended examples with different kinds of shaping operations to demonstrate its applicability. The iterative framework in equation \ref{eq:iter2} is fundamentally a noise attenuation algorithm. The better an operator's ability to remove blending noise and preserve useful signal, the more appropriate it is for shaping. From this point of view, we first created two synthetic sections in different cases. One is a linear event case, with conflicting dip components, and the other is a hyperbolic event case, without crossing events. In order to deal with a more realistic and difficult situation, we created a more complex synthetic model (shown in Figure \ref{fig:test1} and used previously for comparing the sparseness of different transforms) to test the proposed deblending algorithm. For the field data example, we use two common receiver gathers acquired by the OBN technique to generate a numerically blended data test. 

The first three blended synthetic datasets (shown in Figures \ref{fig:data1,datas} to \ref{fig:complexsnrsa}) show nearly perfect deblending results, particularly when the shaping operator is chosen as soft thresholding in the seislet domain. The third blended synthetic datasets shows an acceptable experiments are based on an OBN acquisition, as noted in the beginning of the paper. Thus, each seismic section in the examples corresponds to a common receiver gather. The first example is used simply for testing the denoising ability of each of the shaping operators in the case of crossing events. This example can also demonstrate the deblending performance for common offset gathers, where most seismic events are linear. For conciseness, we show the deblending performance for only one source.
%For concisity, we only display the deblending effects for one profile in each case.

\subsection{Numerically blended synthetic data - linear events}
\inputdir{linear}
Our first synthetic example contains three plane-wave events, with one high-dip-angle event crossing two other events.
The original unblended and numerically blended sections are shown in 
Figure \ref{fig:deblendedfft1,deblendedslet1,deblendedfxdecon1,difffft1,diffslet1,difffxdecon1,errorfft1,errorslet1,errorfxdecon1} shows the deblended results using soft thresholding in the $f-k$ domain, soft thresholding in the seislet domain, and $f-x$ predictive filtering. 
All of these deblending results are generally acceptable despite some artifacts left in Figure \ref{fig:deblendedfft1} and some weak-level noise left in Figure \ref{fig:deblendedfxdecon1}. By computing the difference between the deblended section and the blended section, we can obtain the blending noise section. Comparing the blending noise sections (see Figures \ref{fig:difffft1}-\ref{fig:difffxdecon1}), we find that there is some leakage of useful energy for $f-x$ predictive filtering. Computing the differences between the deblended sections and the unblended sections, we get the estimation error sections, shown in Figures \ref{fig:errorfft1}-\ref{fig:errorfxdecon1}. Compared with the other two shaping approaches, seislet-domain soft thresholding causes a nearly zero estimation error, which indicates a nearly perfect deblending result. The estimation error for $f-x$ predictive filtering is comparatively large, because of the large predictive error problem when several dipping components are taken into consideration \cite[]{yangkang2014}. The small estimation errors in Figure \ref{fig:errorfft1} are caused by spectrum mixture in the $f-k$ domain because some useful energy reside in the low amplitude part that is easy to be removed during soft thresholding. The small estimation errors shown in Figure \ref{fig:errorslet1} are caused by dip estimation error because of the conflicting dips when using plane wave destruction (PWD) algorithm with a single slope \cite[]{pwd}, which is a limitation of seislet-domain denoising approaches, unless a seislet frame is used instead of the seislet transform \cite[]{seislet}. The diagrams for convergence rates are shown in Figure \ref{fig:snrsa}, which demonstrates a superior behavior of seislet-domain soft thresholding in comparison with the other two approaches. In order to make the comparisons fair, we try to find the best deblending performance through the parameter-selection process for corresponding shaping operators. In this case, the percentages we use for $f-k$ domain and seislet domain thresholding are both 8 \%, the filter length we use for $f-x$ predictive filtering is 4 samples. 



\multiplot{2}{data1,datas}{width=0.45\textwidth,height=0.60\textwidth}{Numerically blended synthetic data (linear case). (a) Unblended data. (b) Blended data.} 
\multiplot{9}{deblendedfft1,deblendedslet1,deblendedfxdecon1,difffft1,diffslet1,difffxdecon1,errorfft1,errorslet1,errorfxdecon1}{width=0.2500\textwidth,height=0.2800\textwidth}{Deblending comparison for numerically blended synthetic data (linear case). (a) Deblended result using $f-k$ domain thresholding. (b) Deblended result using seislet-domain thresholding. (c) Deblended result using $f-x$ predictive filtering. (d) Blending noise corresponding to (a). (e) Blending noise corresponding to (b). (f) Blending noise corresponding to (c). (g) Estimation error corresponding to (a). (h) Estimation error corresponding to (b). (i) Estimation error corresponding to (c). }
%\multiplot{9}{deblendedfft2,deblendedslet2,deblendedfxdecon2,difffft2,diffslet2,difffxdecon2,errorfft2,errorslet2,errorfxdecon2}{width=0.2500\textwidth,height=0.2800\textwidth}{Deblending comparison for numerically blended synthetic data. (a) deblended result using $f-k$ domain thresholding. (b) deblended result using seislet-domain thresholding. (c) deblended result using $f-x$ predictive filtering. (d) Blending noise corresponding to (a). (e) Blending noise corresponding to (b). (f) Blending noise corresponding to (c). (g) Estimation error corresponding to (a). (h) Estimation error corresponding to (b). (i) Estimation error corresponding to (c). }
\plot{snrsa}{width=0.8\textwidth}{Diagrams of SNR for synthetic example (linear case). The "+" line corresponds to seislet-domain thresholding. The "o" line corresponds to $f-k$ domain soft thresholding. The "*" line corresponds to $f-x$ predictive filtering.}


\subsection{Numerically blended synthetic data - hyperbolic events}
\inputdir{synthhyper}
Next, we create another synthetic example which contains hyperbolic events without dip conflicts. The unblended and blended data are shown in Figures \ref{fig:hyper1} and \ref{fig:hypers}, respectively. Figure \ref{fig:hyperdeblendedfft1,hyperdeblendedslet1,hyperdeblendedfxdecon1,hyperdifffft1,hyperdiffslet1,hyperdifffxdecon1,hypererrorfft1,hypererrorslet1,hypererrorfxdecon1}
shows the deblending results for the hyperbolic case. Figure \ref{fig:hypersnrsa} shows the diagrams of changing SNR for one source. In this case, the estimation error for the seislet-domain soft thresholding becomes negligible, mainly owing to the successful dip estimation when constructing the seislet transform. The strength of the $f-x$ predictive filtering also increases and its SNR diagram shows a similar behavior as the $f-k$ domain thresholding. The seislet-based shaping still outperforms the other two approaches. In this case, the percentages we use for $f-k$ domain and seislet domain thresholding are both 9 \%, the filter length we use for $f-x$ predictive filtering is 4 samples. 

\multiplot{2}{hyper1,hypers}{width=0.45\textwidth,height=0.60\textwidth}{Numerically blended synthetic data (hyperbolic case). (a) Unblended data. (b) Blended data.}

\multiplot{9}{hyperdeblendedfft1,hyperdeblendedslet1,hyperdeblendedfxdecon1,hyperdifffft1,hyperdiffslet1,hyperdifffxdecon1,hypererrorfft1,hypererrorslet1,hypererrorfxdecon1}{width=0.2500\textwidth,height=0.2800\textwidth}{Deblending comparison for numerically blended synthetic data (hyperbolic case). (a) Deblended result using $f-k$ domain thresholding. (b) Deblended result using seislet-domain thresholding. (c) Deblended result using $f-x$ predictive filtering. (d) Blending noise corresponding to (a). (e) Blending noise corresponding to (b). (f) Blending noise corresponding to (c). (g) Estimation error corresponding to (a). (h) Estimation error corresponding to (b). (i) Estimation error corresponding to (c).}

%\multiplot{9}{hyperdeblendedfft2,hyperdeblendedslet2,hyperdeblendedfxdecon2,hyperdifffft2,hyperdiffslet2,hyperdifffxdecon2,hypererrorfft2,hypererrorslet2,hypererrorfxdecon2}{width=0.2500\textwidth,height=0.2800\textwidth}{Deblending comparison for source 2 of the numerically blended synthetic data (hyperbolic case). (a) deblended result using $f-k$ domain thresholding. (b) deblended result using seislet-domain thresholding. (c) deblended result using $f-x$ predictive filtering. (d) Blending noise corresponding to (a). (e) Blending noise corresponding to (b). (f) Blending noise corresponding to (c). (g) Estimating error corresponding to (a). (h) Estimating error corresponding to (b). (i) Estimating error corresponding to (c). }

\plot{hypersnrsa}{width=0.8\textwidth}{Diagrams of SNR for synthetic example (hyperbolic case). The "+" line corresponds to seislet-domain thresholding. The "o" line corresponds to $f-k$ domain thresholding. The "*" line corresponds to $f-x$ predictive filtering.}

%\multiplot{9}{complexdeblendedfft2,complexdeblendedslet2,complexdeblendedfxdecon2,complexdifffft2,complexdiffslet2,complexdifffxdecon2,complexerrorfft2,complexerrorslet2,complexerrorfxdecon2}{width=0.2500\textwidth,height=0.2800\textwidth}{Deblending comparison for source 2 of the numerically blended synthetic data (complex gather). (a) deblended result using $f-k$ domain thresholding. (b) Deblended result using seislet-domain thresholding. (c) deblended result using $f-x$ predictive filtering. (d) Blending noise corresponding to (a). (e) Blending noise corresponding to (b). (f) Blending noise corresponding to (c). (g) Estimating error corresponding to (a). (h) Estimating error corresponding to (b). (i) Estimating error corresponding to (c). }

\subsection{Numerically blended synthetic data - complex gather}
The third synthetic dataset consists of two complex gathers, which contain both useful seismic reflections and additional components such as ground roll and coherent dipping events. We simulate this example in order to best match the field data. The unblended and blended data are shown in Figures \ref{fig:complex1} and \ref{fig:complexs}, respectively. Figure \ref{fig:complexdeblendedfft1,complexdeblendedslet1,complexdeblendedfxdecon1,complexdifffft1,complexdiffslet1,complexdifffxdecon1,complexerrorfft1,complexerrorslet1,complexerrorfxdecon1}
shows the deblending results for this case. Figure \ref{fig:complexsnrsa} shows the diagrams of changing SNR for both sources. The SNR for the converged deblended data becomes noticeably smaller compared with the previous examples for three different shaping operators respectively, which results from the fact that the seismic gather is no longer ideally sparse as the previous examples. Notice that in the noise sections for $f-k$ domain thresholding (Figure \ref{fig:complexdeblendedfft1}) and the noise sections for $f-x$ predictive filtering (Figure \ref{fig:complexdeblendedfxdecon1}), there exist a certain amount of coherent events. However, for the seislet-domain soft thresholding, there are barely any coherent events. If we look carefully at the error sections corresponding to these three shaping operators, we can find that for the $f-k$ domain thresholding, the estimation error comes from the useful hyperbolic reflections, the coherent dipping events, and the ground roll, for the $f-x$ predictive filtering, the estimation error mainly comes from the useful hyperbolic reflections and the coherent dipping events, but for the seislet-domain soft thresholding, only a small amount of the ground roll and negligible amount of coherent dipping events and deep-water horizontal reflections are left on the error sections, which is not important for the whole processing tasks. We can conclude that for complex datasets like this synthetic example, seislet-domain soft thresholding is the preferable approach for shaping regularization.
In this case, the percentages we use for $f-k$ domain and seislet domain thresholding are both 20 \%, the filter length we use for $f-x$ predictive filtering is 4 samples. 

\inputdir{synthcomplex}
\multiplot{2}{complex1,complexs}{width=0.45\textwidth,height=0.60\textwidth}{Numerically blended synthetic data (complex gather). (a) Unblended data. (b) Blended data.}

\multiplot{9}{complexdeblendedfft1,complexdeblendedslet1,complexdeblendedfxdecon1,complexdifffft1,complexdiffslet1,complexdifffxdecon1,complexerrorfft1,complexerrorslet1,complexerrorfxdecon1}{width=0.2500\textwidth,height=0.2800\textwidth}{Deblending comparison for numerically blended synthetic data (complex gather). (a) Deblended result using $f-k$ domain thresholding. (b) Deblended result using seislet-domain thresholding. (c) Deblended result using $f-x$ predictive filtering. (d) Blending noise corresponding to (a). (e) Blending noise corresponding to (b). (f) Blending noise corresponding to (c). (g) Estimation error corresponding to (a). (h) Estimation error corresponding to (b). (i) Estimation error corresponding to (c). }

\plot{complexsnrsa}{width=0.8\textwidth}{Diagrams of SNR for synthetic example (complex gather). The "+" line corresponds to seislet-domain thresholding. The "o" line corresponds to $f-k$ domain thresholding. The "*" line corresponds to $f-x$ predictive filtering.}

\subsection{Numerically blended field data }

Finally, we use a field data example to further test the effectiveness for our proposed algorithm. The field data is similar in appearance to the previous synthetic example. Because of the previous test, we only used seislet-domain soft thresholding as the shaping operator.
% Note that, in the case of deblending, these "noise" are also treated as useful energy. 
The two blended data are shown in Figures \ref{fig:blended763} and \ref{fig:blended754} and appear noisy.
 After 30 iterations of seislet-domain soft thresholding, the deblending results are shown in Figures \ref{fig:shotdeblendedslet1} and \ref{fig:shotdeblendedslet2}.  The intense interference in the shallow part has been removed to a large extent. The deep-water reflection becomes much clearer because of a significant drop in the noise energy for the whole profile. From the noise sections, we can observe only a small amount of ground roll, which is analogous to the results of the previous synthetic test, and a even less amount of direct waves and shallow part horizontal reflections, which is not significant. The $SNR$ defined in equation \ref{eq:diff} obtained an increase from 1.00 $dB$ to 5.50 $dB$ for the first source and from 0.83 $dB$ to 5.50 $dB$ for the second source. The error sections for this field data test are not given since the unblended data for this test contain much random noise, which can not be estimated.
However, from the point of view of random noise attenuation, which is concerned with the signal content of the denoised section and the randomness of the noise section, the deblending result of the field data test is acceptable. In this case, the percentage we use for seislet domain thresholding is 18\%.

The main computational cost of the proposed approach lays on the forward and inverse seislet transforms. As analyzed by \cite{seislet}, the seislet transform has linear $O(N)$ cost. It can be more expensive than fast Fourier transform and digital wavelet transform, but is still comfortably efficient in practice. Considering that for the 2D seislet transform, the main cost may not be in the transform itself but in the iterative estimation of the slope fields, we update slope estimation every several iterations (e.g., every 5 iterations in this field data example) to reduce the computational cost.

%Comparing blending noise sections Figures \ref{fig:shotdifffft2}-\ref{fig:shotdifffxdecon2} and Figures \ref{fig:shotdifffft1}-\ref{fig:shotdifffxdecon1}, and estimation error sections Figures \ref{fig:shoterrorfft2}-\ref{fig:shoterrorfxdecon2} and Figures \ref{fig:shoterrorfft1}-\ref{fig:shoterrorfxdecon1} we find the Fourier domain method does not preserve much of the gound roll and small amount of reflections. The seislet domain method harms very small amount of reflection energy and nearly no ground roll. The $f-x$ predictive filtering harms the ground roll and useful reflections both to a large extent. The diagrams of changing SNR in Figure \ref{fig:shotsnrsb,shotsnrsa} are consistent with Figures \ref{fig:shotdeblendedfft2,shotdeblendedslet2,shotdeblendedfxdecon2,shotdifffft2,shotdiffslet2,shotdifffxdecon2,shoterrorfft2,shoterrorslet2,shoterrorfxdecon2} and \ref{fig:shotdeblendedfft1,shotdeblendedslet1,shotdeblendedfxdecon1,shotdifffft1,shotdiffslet1,shotdifffxdecon1,shoterrorfft1,shoterrorslet1,shoterrorfxdecon1} in that $f-x$ predictive filtering obtains a very small gain in the SNR. The $f-k$ domain shaping and seislet-domain shaping appear closer to each other but the seislet domain shaping still outperms both of the other two approaches. The stripe-like estimation errors in the error sections shown in Figures \ref{fig:shoterrorfft2}-\ref{fig:shoterrorfxdecon2} and \ref{fig:shoterrorfft1}-\ref{fig:shoterrorfxdecon1} are due to the strong interference in the shallow part of the blended seismic profile. However, according to the results shown in Figures \ref{fig:shotdeblendedslet2} and \ref{fig:shotdeblendedslet1}, those shallow part interference are getting removed out to a large extent.


\inputdir{fairfield-initmfnew}
\multiplot{6}{blended763,blended754,shotdeblendedslet2,shotdeblendedslet1,shotdiffslet2,shotdiffslet1}{width=0.42\textwidth,height=0.3600\textwidth}{Deblending comparison for the real data. (a) Blended source 1. (b) Blended source 2. (c) Deblended source 1. (d) Deblended source 2. (e) Blending noise for source 1. (f) Blending noise for source 2.}


%\multiplot{4}{unblended763,blended763,unblended754,blended754}{width=0.45\textwidth,height=0.60\textwidth}{Numerically blended field data. (a) Original unblended source 1. (b) The same section as (a) after blending. (c) Original unblended source 2. (d) The same section as (c) after blending. }

%\multiplot{9}{shotdeblendedfft2,shotdeblendedslet2,shotdeblendedfxdecon2,shotdifffft2,shotdiffslet2,shotdifffxdecon2,shoterrorfft2,shoterrorslet2,shoterrorfxdecon2}{width=0.2500\textwidth,height=0.2800\textwidth}{Deblending comparison for source 1 of the real data. (a) deblended result using $f-k$ domain masking operation. (b) deblended result using seislet domain thresholding. (c) deblended result using $f-x$ predictive filtering. (d) Blending noise corresponding to (a). (e) Blending noise corresponding to (b). (f) Blending noise corresponding to (c). (g) Estimating error corresponding to (a). (h) Estimating error corresponding to (b). (i) Estimating error corresponding to (c). }
%\multiplot{9}{shotdeblendedfft1,shotdeblendedslet1,shotdeblendedfxdecon1,shotdifffft1,shotdiffslet1,shotdifffxdecon1,shoterrorfft1,shoterrorslet1,shoterrorfxdecon1}{width=0.2500\textwidth,height=0.2800\textwidth}{Deblending comparison for source 2 of the real data. (a) deblended result using $f-k$ domain masking operation. (b) deblended result using seislet domain thresholding. (c) deblended result using $f-x$ predictive filtering. (d) Blending noise corresponding to (a). (e) Blending noise corresponding to (b). (f) Blending noise corresponding to (c). (g) Estimating error corresponding to (a). (h) Estimating error corresponding to (b). (i) Estimating error corresponding to (c). }

%\multiplot{2}{shotsnrsb,shotsnrsa}{width=0.45\textwidth}{Diagrams of SNR for the field data example. The "+" line corresponds to seislet domain soft thresholding. The "o" line corresponds to $f-k$ domain mask operation. The "*" line corresponds to $f-x$ predictive filtering. (a) For source 1. (b)  For source 2.}


%\section{Discussion}


%The experimental field data is so complicated that the deblending results of just acceptable rahter than perfect because of the certain amount of esimation error. However, the motivation of this paper is to introduce a new version of iterative framework that is useful and promising in the deblending of simultaneous-source seismic data. The further polishing of this algorithm in order to get better and perfect deblending result is beyond the scope of this paper. In fact, there exists several issues waiting for further researches, for example, like further improving the thresholding or masking strategies, improving the local dip estimation using a more robust version of PWD, which can in turn helps to improve the sparsity of seislet transform. 


\section{Conclusions}
We have proposed a novel iterative framework, which offers a flexible way to control deblending using sparsity or coherency constraints.  
%The blended seismic profile may be too complicated or relatively simpler due to different acquisition or subsurface structure. 
When the seismic data are relatively clean and do not contain much coherent noise, $f-k$ domain sparsity-promoting operator or $f-x$ predictive filtering might be adequate to handle the blending noise. However, when the blended data become more complicated, a more robust sparsity or coherency-promoting tool should be utilized. The seislet transform has an inherent ability to compress coherent seismic data, because it is generated based on predictability between neighboring traces using the local slope information. As long as we can get an acceptable slope estimation, the seislet-transformed data appears sparse.
%We have presented an iterative approach to deblend seismic data from simultaneous sources.
%using shaping regularization. 
%The principle of our approach is treating the problem of deblending as an estimation problem, and then using shaping regularization to constrain the models when iteratively solving the problem. The shaping operator can be chosen according to different criterions such as sparsity or coherency. We have derived the mathematical formulation of this method and used both numerically-blended synthetic example and field data example to test it. 
Our experiments indicate that it is possible to get accurate results within a small number of iterations when an appropriate shaping operator is taken. 
%While those common coherency or sparsity promoting operators all can work effectively, 
%Seislet domain soft-thresholding operator appears to be more robust regardless of the complexity of the input blended data. 

%In addition, the main advantage of shaping regularization is its relative ease of selecting $S$ in comparison the regularization operators in other 
%We also demonstrate that for the real data, when compared with the deblending result using soft thresholding in the frequency-wavenumber domain as the shaping operator, soft thresholding in the seislet domain can preserve more geological features of the original unblended data, which suggests a superior characteristics of seislet transform in the selection of shaping operator for our proposed method.
%\inputdir{blendmsk}
\section{Acknowledgments}
We thank FairfieldNodal for providing the field data used in this study. We thank Alexander Klokov, Karl Schleicher, Parvaneh Karimi, Araz Mahdad, Josef Paffenholz, David Hays, Paul Docherty and Le-wei Mo for helpful discussions. We also thank Sam Kaplan, Chengbo Li, Jinkun Cheng, Jeff Shragge, Evert Slob, and one anonymous reviewer for their constructive suggestions, which helped improve this paper. 
%We are grateful for developers of Madagascar software packages for providing accessible codes. 

\inputdir{synth}

\newpage
\onecolumn
\bibliographystyle{seg}
\bibliography{simul}
\newpage
\append{Review of seislet transform}
\cite{fomel4} and \cite{seislet} proposed a digital wavelet-like transform, which is defined with the help of the wavelet-lifting scheme \cite[]{lifting} combined with local plane-wave destruction. The wavelet-lifting utilizes predictability of even traces from odd traces of 2-D seismic data and finds a difference $\mathbf{r}$ between them, which can be expressed as:
\begin{equation}
\label{eq:one}
\mathbf{r}=\mathbf{o}-\mathbf{P\left[e\right]},
\end{equation}
where $\mathbf{P}$ is the prediction operator.
A coarse approximation $\mathbf{c}$ of the data can be achieved by updating the even component:
\begin{equation}
\label{eq:two}
\mathbf{c}=\mathbf{e}+\mathbf{U\left[r\right]},
\end{equation}
where $\mathbf{U}$ is the updating operator.

The digital wavelet transform can be inverted by reversing the lifting-scheme operations as follows:
\begin{equation}
\label{eq:three}
\mathbf{e}=\mathbf{c}-\mathbf{U\left[r\right]},
\end{equation}
\begin{equation}
\label{eq:four}
\mathbf{o}=\mathbf{r}+\mathbf{P\left[e\right]}.
\end{equation}

The foward transform starts with the finest scale (the original sampling) and goes to the coarsest scale. The inverse transfrom starts with the coarsest scale and goes back to the finest scale. At the start of forward transform, $\mathbf{e}$ and $\mathbf{o}$ corresponds to the even and odd traces of the data domain. At the start of the inverse transform, $\mathbf{c}$ and $\mathbf{r}$ will have just one trace of the coarsest scale of the seislet domain.

The above prediction and update operators can be defined, for example, as follows:
\begin{equation}
\label{eq:five}
\mathbf{P}\left[\mathbf{e}\right]_k=\left(\mathbf{P}^{(+)}_k\left[\mathbf{e}_{k-1}\right]+\mathbf{P}^{(-)}_k\left[\mathbf{e}_k\right]\right)/2,
\end{equation}
and
\begin{equation}
\label{eq:six}
\mathbf{U}\left[\mathbf{r}\right]_k=\left(\mathbf{P}^{(+)}_k\left[\mathbf{r}_{k-1}\right]+\mathbf{P}^{(-)}_k\left[\mathbf{r}_k\right]\right)/4,
\end{equation}
where $\mathbf{P}^{(+)}_k$ and $\mathbf{P}^{(-)}_k$ are operators that predict a trace from its left and right neighbors, correspondingly, by shifting seismic events according to their local slopes. 
This scheme is analogous to CDF biorthogonal wavelets \cite[]{cohen1992}. The predictions need to operate at different scales, which means different separation distances between traces. Taken through different scales, equations \ref{eq:one}-\ref{eq:six} provide a simple definition for the 2D seislet transform.  More accurate versions are based on other schemes for the digital wavelet transform \cite[]{liuyang20091}.





















