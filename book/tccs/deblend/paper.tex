\published{Geophysics, 79, no. 5, V179-V189, (2014)}

\title{Iterative deblending of simultaneous-source seismic data using seislet-domain shaping regularization}
\renewcommand{\thefootnote}{\fnsymbol{footnote}}
%\author{Yangkang Chen\footnotemark[1], Sergey Fomel\footnotemark[1] and Jingwei Hu\footnotemark[1]}
\author{Yangkang Chen, Sergey Fomel, and Jingwei Hu}
% width=0.2500\textwidth, height=0.2800\textwidth good
% width=0.2500\textwidth, height=0.2800\textwidth
% width=0.2300\textwidth, height=0.2700\textwidth

\ms{GEO-2013-449}

\address{
Bureau of Economic Geology \\
John A. and Katherine G. Jackson School of Geosciences \\
The University of Texas at Austin \\
University Station, Box X \\
Austin, TX 78713-8924 \\
}

\lefthead{Chen et al.}
\righthead{Deblending using shaping regularization}
\footer{TCCS-7}
\maketitle

\begin{abstract}
We used a novel iterative estimation scheme for separation of blended seismic data from simultaneous sources. The scheme is based on an augmented estimation problem, which can be solved by  iteratively constraining the deblended data using shaping regularization in the seislet domain. We formulate the forward modeling operator in the common receiver domain, where two sources are assumed to be blended using a random time-shift dithering approach. The nonlinear shaping-regularization framework offers some freedom in designing a shaping operator to constrain the model in an underdetermined inverse problem. We design the backward operator and the shaping operator for the shaping regularization framework. The backward operator can be optimally chosen as a half of the identity operator in the two-source case, and the shaping operator can be chosen as coherency-promoting operator. Three numerically blended synthetic datasets and one numerically blended field dataset demonstrate the high-performance deblending effect of the proposed iterative framework. Compared with alternative $f-k$ domain thresholding and $f-x$ predictive filtering, seislet-domain soft thresholding exhibits the most robust behavior.
\end{abstract}

\section{Introduction}

The simultaneous-source technique aims at removing the limitation of no interference between adjacent shots by allowing more than one source to be shot simultaneously. Thus it can reduce the acquisition period and increase spatial sampling \cite[]{berk}. Because of its economic benefits and technical challenges, this technique has attracted significant attention of researchers in both industry and academia \cite[]{moore2008,mahdad2011,abma,mediandeblend,deblendinv}. The biggest issue involved in simultaneous-source processing is an intense crosstalk noise between adjacent shots, which poses a challenge for conventional processing. One way to deal with this issue is to use a first-separate and second-process strategy, which is also known as \emph{deblending} \cite[]{pana1}. The other way is by direct imaging and waveform inversion \cite[]{berkhout2012,choi2012,plessix2012,guitton2012,zhiguang2014}. In this paper, we focus on the deblending approach.

Different filtering and inversion methods have been applied previously to deblend seismic data. Filtering methods utilize the property that the coherency of the simultaneous-source data varies in different domains. Therefore, one can get unblended data by filtering out randomly distributed blending noise in some transform domains, where one source record is coherent and the others are not \cite[]{gary,iter,mediandeblend}. Inversion methods treat the separation problem as an estimation problem, which aims at estimating the desired unknown unblended data. Because of the ill-posed nature of such estimation problems, a regularization term is usually required \cite[]{pana2}. The regularization term can be chosen as a sparsity promotion in a sparsifying transformed domain \cite[]{abma2010}. \cite{roald} proposed to distribute all energy in the shot records by reconstructing individual shot records at their respective locations. \cite{mahdad2011} introduced an iterative estimation and subtraction scheme that combines the properties of filtering and inversion methods and exploits the fact that the characteristics of the blending noise differ in different domains. One choice is to transform seismic data from the common-shot domain to common-receiver, common-offset or common-midpoint domain. \cite{proj} proposed a separation technique called the alternating projection method, and demonstrated it to be robust in the presence of aliasing. 

In this paper, we propose a novel iterative estimation scheme for the separation of blended seismic data. We construct an augmented estimation problem, then use shaping regularization \cite[]{fomel2,fomel3} to constrain the characteristics of the model during the iteration process for obtaining a suitable estimation result.
We adopt seislet-domain \cite[]{seislet} soft thresholding as a robust shaping operator to remove crosstalk noise and at the same time to preserve useful components of seismic data. Shaping regularization maps each model into a more admissible model at each iteration and allows us to solve the deblending problem with a small number of iterations. 

This paper is organized as follows: we first present a formulation of numerical blending using an augmented block-matrix equation. We then incorporate shaping regularization to solve the forward equation iteratively and discuss the selection of the backward operator and shaping operator involved in the shaping-regularization iterative framework. Finally, we test the proposed iterative framework on three numerically blended synthetic datasets and one numerically blended field dataset and compare three different choices of the shaping operator: $f-k$ domain thresholding, $f-x$ predictive filtering, and seislet domain thresholding. 
 
\section{Deblending using shaping regularization}
\subsection{Numerical blending}

We assume that the seismic record is blended using two independent sources, which correspond to two shooting vessels in the ocean bottom nodes (OBN) acquisition \cite[]{obn}. Here, one source means a collection of shots from one shooting vessel. The
two sources shoot pseudosynchronously, which means that each shot in one source has a random time dithering compared with the corresponding shot in another source.  By precisely picking the shooting time of each shot of one source at the long seismic record on the node, we can get one common receiver gather. Using the second source, we get another gather.
Thus, the forward problem can be formulated as follows:
\begin{equation}
\label{eq:inv}
\mathbf{d}=\mathbf{d}_1+\mathbf{Td}_2.
\end{equation}
Here, $\mathbf{d}_1$ and $\mathbf{d}_2$ denote the seismic records to be separated out, $\mathbf{d}$ is the blended data, and $\mathbf{T}$ denotes the dithering operator. Note that we perform the processing in the common-receiver domain, because each blended record in this domain is coherent for one source and incoherent for another \cite[]{gary}. In this case, $\mathbf{d}$ is usually referred to as the pseudodeblended data \cite[]{mahdad2011}, which means picking traces from the original blended field record according to the shooting time of one source to form a common receiver gather with one source coherent and the other one incoherent. 
We propose to augment equation \ref{eq:inv} with another equation through applying the inverse dithering operator $\mathbf{T}^{-1}$:
\begin{equation}
\label{eq:inv1}
\mathbf{T}^{-1}\mathbf{d}=\mathbf{T}^{-1}\mathbf{d}_1+\mathbf{d}_2.
\end{equation}
By combining equations \ref{eq:inv} and \ref{eq:inv1}, we formulate an augmented estimation problem:
\begin{equation}
\label{eq:esti}
\mathbf{Fm}=\mathbf{\tilde{d}},
\end{equation}
where
\begin{eqnarray}
\label{eq:note}
\mathbf{\tilde{d}}=
\left[\begin{array}{cc}
\mathbf{d}\\
\mathbf{T}^{-1}\mathbf{d}
\end{array}\right],
\quad
\mathbf{F}=
\left[\begin{array}{cc}
\mathbf{I} 	& \mathbf{T}\\
\mathbf{T}^{-1} & \mathbf{I}
\end{array}\right],
\quad
\mathbf{m}=
\left[\begin{array}{cc}
\mathbf{d}_1\\
\mathbf{d}_2
\end{array}\right],
\end{eqnarray}
and $\mathbf{I}$ is the identity operator.

We choose to solve equation \ref{eq:esti} rather than equation \ref{eq:inv} because equation \ref{eq:esti} is a more convenient form to use in the following derivations.

\subsection{Shaping regularization}

The unknown $\mathbf{m}$ in equation \ref{eq:esti} can be recovered iteratively using shaping regularization:
\begin{equation}
\label{eq:iter2}
\mathbf{m}_{n+1}=\mathbf{S}[\mathbf{m}_n+\mathbf{B}(\mathbf{\tilde{d}}-\mathbf{Fm}_n)],
\end{equation}
where operator $\mathbf{S}$ shapes the estimated model into the space of admissible models at each iteration \cite[]{fomel2,fomel3} and $\mathbf{B}$ is the backward operator that provides an inverse mapping from data space to model space.
\cite{daubechies} prove that, if $\mathbf{S}$ is a nonlinear thresholding operator \cite[]{donoho}, $\mathbf{B}=\mathbf{F}^T$ where $\mathbf{F}^T$ is the adjoint operator of $\mathbf{F}$, iteration \ref{eq:iter2} converges to the solution of equation \ref{eq:leastreg} with $L_1$ regularization term:
\begin{equation}
\label{eq:leastreg}
\min_{\mathbf{m}} \parallel \mathbf{Fm-\tilde{d}} \parallel_2^2 +\mu\parallel\mathbf{A}^{-1}\mathbf{m}\parallel_1,
\end{equation}
where $\mu$ is the threshold and $\mathbf{A}^{-1}$ denotes a sparsity-promoting transform. 
A better choice for $\mathbf{B}$ is the pseudoinverse of $\mathbf{F}$: $\mathbf{B}=(\mathbf{F}^T\mathbf{F})^{-1}\mathbf{F}^T$ \cite[]{daubechies2008}.

\subsection{Performance evaluation and convergence rate}
Combining equations \ref{eq:esti}, \ref{eq:note} and \ref{eq:iter2}, we get: 
\begin{equation}
\label{eq:main}
\left[\begin{array}{cc}
\mathbf{d}_1\\
\mathbf{d}_2
\end{array}\right]_{n+1}=\mathbf{S}
\left[
\left[\begin{array}{cc}
\mathbf{d}_1\\
\mathbf{d}_2
\end{array}\right]_n+
\mathbf{B}\left[\left[\begin{array}{cc}
\mathbf{d}\\
\mathbf{T}^{-1}\mathbf{d}
\end{array}\right]-\left[\begin{array}{cc}
\mathbf{I}	& \mathbf{T}\\
\mathbf{T}^{-1} & \mathbf{I}
\end{array}\right]
\left[\begin{array}{cc}
\mathbf{d}_1\\
\mathbf{d}_2
\end{array}\right]_n
\right]\right],
\end{equation}
where $\mathbf{S}$ is a block operator that takes the form
$[\mathbf{S}_1\quad \mathbf{0};\mathbf{0}\quad\mathbf{S}_2]$, and $\mathbf{S}_1$ and $\mathbf{S}_2$ correspond to the shaping operators for $\mathbf{d}_1$ and $\mathbf{d}_2$, respectively. Using equation \ref{eq:main} and performing appropriate iterations, we aim to get an estimate of unblended seismic data.

To test the convergence performance and accuracy of iteration \ref{eq:main}, we use the following measure \cite[]{hennenfent2006}:
\begin{equation}
\label{eq:diff}
SNR_{i,n}=10\log_{10}\frac{\Arrowvert \mathbf{d}_i \Arrowvert_2^2}{\Arrowvert \mathbf{d}_i-\mathbf{d}_{i,n}\Arrowvert_2^2},
\end{equation}
where $SNR_{i,n}$ stands for signal-to-noise ratio of $i$th source after $n$th iteration, $\mathbf{d}_{i,n}$ denotes the estimated model of $i$th source after $n$ iterations, $\mathbf{d}_i$ denotes the true model for $i$th source and $\parallel \cdot \parallel_2^2$ denotes the squared $L_2$ norm of a function.

\section{Backward operator}
In equation \ref{eq:iter2}, $\mathbf{B}$ is an approximate inverse of $\mathbf{F}$. 
Recall that the dithering operator applies a time-domain random time shift to the input seismic data. Taken in the frequency domain, the dithering operator takes the following form: 
\begin{equation}
\label{eq:ditherf}
\mathbf{T} = \mathbf{\mathcal{F}}^{-1}\mathbf{P}\mathbf{\mathcal{F}},
\end{equation}
where $\mathbf{\mathcal{F}}$ and $\mathbf{\mathcal{F}}^{-1}$ are forward and inverse Fourier transforms, respectively, and $\mathbf{P}$ is a $N\times N$ diagonal block phase-shift operator given by
\begin{equation}
\label{eq:phaseshift}
\mathbf{P}=diag(\mathbf{P}_1, \mathbf{P}_2, \mathbf{P}_3, \cdots, \mathbf{P}_N),
\end{equation}
where 
$\mathbf{P}_n$ denotes the individual phase shift operator for $n$th trace and can be expressed as a $M\times M$ diagonal matrix:
\begin{equation}
\label{eq:phaseshift1}
\mathbf{P}_n = diag(\overbrace{1,1,1, \cdots, 1}^{M})*\exp(-i\omega\delta t_n).
\end{equation}

Here, $w$ denotes the angular frequency, $\delta t_n$ denotes the random dithering time of $n$th trace, and $M$ and $N$ in equations \ref{eq:phaseshift} and \ref{eq:phaseshift1} denote the number of temporal samples and number of traces, respectively. $diag(\cdot)$ denotes a diagonal matrix. 

Considering that the Fourier operator (with symmetric normalization) and the phase shift operator are both unitary, which means $\mathbf{\mathcal{F}}^{-1}=\mathbf{\mathcal{F}}^{T}$ and $\mathbf{P}^{-1}=\mathbf{P}^T$, it is easy to see that 
\begin{equation}
\label{eq:unitary}
\begin{split}
\mathbf{T}^T &=(\mathbf{\mathcal{F}}^{-1}\mathbf{P}\mathbf{\mathcal{F}})^T =\mathbf{\mathcal{F}}^T\mathbf{\mathbf{P}}^T\mathbf{\mathcal{F}} =(\mathbf{\mathcal{F}}^{-1}\mathbf{P}\mathbf{\mathcal{F}})^{-1} =\mathbf{T}^{-1}.
\end{split}
\end{equation}
Thus, we conclude that the dithering operator is also a unitary operator.\\
Furthermore we notice that
\begin{equation}
\label{eq:back2}
\mathbf{F}^T=
\left[\begin{array}{cc}
\mathbf{I} 	& \mathbf{T}\\
\mathbf{T}^{-1} & \mathbf{I}
\end{array}\right]^T=
\left[\begin{array}{cc}
\mathbf{I} 	& \mathbf{T}^{-T}\\
\mathbf{T}^{T} & \mathbf{I}
\end{array}\right]=
\left[\begin{array}{cc}
\mathbf{I} 	& \mathbf{T}\\
\mathbf{T}^{-1} & \mathbf{I}
\end{array}\right]=
\mathbf{F}, \nonumber 
\end{equation}
and:
\begin{equation}
\label{eq:back3}
\mathbf{F}^T\mathbf{F}=\left[\begin{array}{cc}
\mathbf{I} 	& \mathbf{T}\\
\mathbf{T}^{-1} & \mathbf{I}
\end{array}\right]
\left[\begin{array}{cc}
\mathbf{I} 	& \mathbf{T}\\
\mathbf{T}^{-1} & \mathbf{I}
\end{array}\right]=
2\left[\begin{array}{cc}
\mathbf{I} 	& \mathbf{T}\\
\mathbf{T}^{-1} & \mathbf{I}
\end{array}\right]=
2\mathbf{F}.
\end{equation}

The least-squares solution of equation \ref{eq:esti} is therefore:
\begin{equation}
\label{eq:solu}
\mathbf{\hat{m}}=(\mathbf{F}^T\mathbf{F})^{-1}\mathbf{F}^{T}\mathbf{\tilde{d}}=\frac{1}{2}\mathbf{F}^{-1}\mathbf{F}^T\mathbf{\tilde{d}}=\frac{1}{2}\mathbf{\tilde{d}}.
\end{equation}

According to equation \ref{eq:solu}, an appropriate choice for $\mathbf{B}$ is simply 
$\mathbf{B}=\frac{1}{2}[\mathbf{I}\quad\mathbf{0};\mathbf{0}\quad\mathbf{I}]$. This form of the derived backward operator is also referred to as scaled pseudodeblending \cite[]{arazthesis}.

The dithering operator is unitary only if the time-shift range is small and so the constructive summation of the useful components (events) between different traces can be ignored. Even if this condition isn't fully met, we can use the concept of interference to generalize the meaning of the dithering operator $\mathbf{T}$. Although, in this case, the backward operator might not be most appropriately chosen as half of the identity operator, we can still use it as an approximation.

\section{Shaping operator}
The shaping operator $\mathbf{S}$ in equation \ref{eq:iter2} can be chosen as a coherency-promoting operator, which serves as a flexible constraint on the estimated model.
Any coherency-promoting tool such as $f-x$ predictive filtering \cite[]{canales1984,sacchi2000,galbraith2012,yangkang2014} or median filter \cite[]{liuyang2009tvmf,mediandeblend,yike2013} can be utilized to preserve the coherent useful subsurface reflection and at the same time to remove incoherent blending noise. 

Another approach to promote coherency is to promote sparseness in an appropriate transform domain. To enforce sparsity, a transform domain thresholding operation can also be chosen as the shaping operator as long as the data in the transformed domain is sparse \cite[]{mallat2009,candes2010}. Instead of a thresholding operator, we can also use a mask operator to compress the transformed domain \cite[]{mostafa2010,liuyang2012}. A sparsity-promoting shaping operator can be defined as:
\begin{align}
\label{eq:sparse1}
\mathbf{S}_i =\mathbf{A}\mathbf{\mathcal{T}}_{\mathbf{\gamma}_i}[\mathbf{A}^{-1}], 
\end{align}
where $i$ denotes the $i$th source, $\mathbf{A}^{-1}$ and $\mathbf{A}$ are forward and inverse sparsity-promoting transforms and $\mathbf{\mathcal{T}}_{\gamma_i}$ corresponds to a mask operator or thresholding operator with an input parameter $\gamma_i$ in the transformed domain.

Mask operator can be chosen to preserve small-scale components and remove large-scale components. It takes the following form:
\begin{equation}
\label{eq:mask}
\mathbf{\mathcal{M}}_{\gamma_i}(v(\mathbf{x})) = \left\{ \begin{array}{ll}
v(\mathbf{x}) & \text{for}\quad  s(\mathbf{x}) < \gamma_i  \\
0	      & \text{for}\quad  s(\mathbf{x}) \ge \gamma_i
\end{array}\right.,
\end{equation}
where $\mathbf{x}$ is a position vector in the transformed domain, $v(\mathbf{x})$ denotes the amplitude value of point $\mathbf{x}$, $s(\mathbf{x})$ denotes the scale of point $\mathbf{x}$ and $\mathbf{\mathcal{M}}_{\gamma_i}$ corresponds to the mask operator with a scale limitation $\gamma_i$. When the sparsity-promoting transform is the Fourier transform, the scale defined in the mask operator shown in equation \ref{eq:mask} corresponds to the frequency and wavenumber band.

Thresholding operators can be divided into two types: soft and hard. Soft thresholding or shrinkage aims to remove data whose value is smaller than a certain level and subtract the other data values by this level \cite[]{donoho1995}. Hard thresholding simply removes data with small values. A soft thresholding operator takes the following form:
\begin{equation}
\label{eq:soft}
\mathbf{\mathcal{S}}_{\gamma_i}(v(\mathbf{x})) = \left\{ \begin{array}{ll}
v(\mathbf{x})-\gamma_i \frac{v(\mathbf{x})}{|v(\mathbf{x})|} & \text{for}\quad  |v(\mathbf{x})| > \gamma_i  \\
0			      & \text{for}\quad  |v(\mathbf{x})| \le \gamma_i
\end{array}\right.,
\end{equation}
where $\mathbf{\mathcal{S}}_{\gamma_i}$ corresponds to the soft thresholding operator with a threshold value $\gamma_i$.

Similarly, a hard thresholding operator takes the form:
\begin{equation}
\label{eq:hard}
\mathbf{\mathcal{H}}_{\gamma_i}(v(\mathbf{x})) = \left\{ \begin{array}{ll}
v(\mathbf{x})  & \text{for}\quad  |v(\mathbf{x})| > \gamma_i  \\
0			      & \text{for}\quad |v(\mathbf{x})|  \le \gamma_i
\end{array}\right.,
\end{equation}
where $\mathbf{\mathcal{H}}_{\gamma_i}$ corresponds to the hard thresholding operator with a threshold value $\gamma_i$.

The mask operator can be more efficient because it is linear and requires only the scale coefficient below which data values are preserved. The thresholding operator needs to compare the amplitude value of each transformed domain point with a predefined coefficient. However, the mask operator is more difficult to design when the signal and noise coefficients are both spread across the transformed domain. Therefore, in the case of deblending, we prefer to use the thresholding operator rather than the mask operator. The selection criteria of $\gamma_i$ in the above definitions of thresholding operators (both soft and hard) leads to different kinds of thresholding strategies, which may result in different thresholding performances (convergence rate and quality) \cite[]{pengliang2013}. Some of the common iterative thresholding strategies are constant-value thresholding, linear-decreasing thresholding, exponential-decreasing thresholding, etc. \cite[]{jianjun2010}.  In our paper, we use percentile thresholding \cite[]{dian2008,pengliang20121}, which is convenient to implement and helps accelerate the convergence \cite[]{pengliang20121}.

\subsection{Comparison of sparsity-promoting transforms}
The best-known sparsity-promoting transforms are the Fourier and wavelet transform. \cite{seislet} proposed a sparsity-promoting transform called \emph{seislet} transform. The specific adaptation for seismic data makes the seislet transform appealing to seismic data processing. In the seislet domain, useful events and blending noise reside at different scales and the useful signal tends to form a more compact region. We provide a brief review of the seislet transform in Appendix A.

In order to illustrate the comparative sparseness of different transforms, we first create a simple synthetic data (Figure \ref{fig:test1}). Figure \ref{fig:ft,wlet,slet0,sigcoef} shows different transformed domains for the data. Figure \ref{fig:sigcoef} shows a comparison between the decay of sorted coefficients in the 2-D Fourier transform, 2-D wavelet transform, and 2-D seislet transform. The 2-D Fourier transform in this case means the $f-k$ transform. The 2-D wavelet transform means implementing the 1-D wavelet transform along the temporal direction first and along the spatial direction second. The 2-D seislet transform means implementing the seislet transform along the spatial direction first and 1-D seislet transform along the temporal direction second. Our experiments show that the seislet coefficients decay significantly faster than coefficients of the other two transforms, which indicates a more compact structure of the seislet domain. The shaping operation is thus preferably chosen as the thresholding or mask operation in the seislet domain.

\inputdir{hyper}
\plot{test1}{width=0.7\textwidth}{A synthetic seismic profile.}
\multiplot{4}{ft,wlet,slet0,sigcoef}{width=0.45\textwidth,height=0.35\textwidth}{Comparison among different sparsity-promoting transforms. (a) 2-D Fourier transform domain. (b) 2-D Wavelet transform domain. (c) 2-D Seislet transform domain. (d) Coefficients decreasing diagram.}

\section{Examples}
In this section, in order to test the effectiveness of the proposed iterative framework defined in equation \ref{eq:iter2}, we create three numerically blended examples with different kinds of shaping operations to demonstrate its applicability. The iterative framework in equation \ref{eq:iter2} is fundamentally a noise attenuation algorithm. The better an operator's ability to remove blending noise and preserve useful signal, the more appropriate it is for shaping. From this point of view, we first created two synthetic sections in different cases. One is a linear event case, with conflicting dip components, and the other is a hyperbolic event case, without crossing events. In order to deal with a more realistic and difficult situation, we created a more complex synthetic model (shown in Figure \ref{fig:test1} and used previously for comparing the sparseness of different transforms) to test the proposed deblending algorithm. For the field data example, we use two common receiver gathers acquired by the OBN technique to generate a numerically blended data test. 

The first three blended synthetic datasets (shown in Figures \ref{fig:data1,datas} to \ref{fig:complexsnrsa}) show nearly perfect deblending results, particularly when the shaping operator is chosen as soft thresholding in the seislet domain. The third blended synthetic datasets shows an acceptable experiments are based on an OBN acquisition, as noted in the beginning of the paper. Thus, each seismic section in the examples corresponds to a common receiver gather. The first example is used simply for testing the denoising ability of each of the shaping operators in the case of crossing events. This example can also demonstrate the deblending performance for common offset gathers, where most seismic events are linear. For conciseness, we show the deblending performance for only one source.

\subsection{Numerically blended synthetic data - linear events}
\inputdir{linear}
Our first synthetic example contains three plane-wave events, with one high-dip-angle event crossing two other events.
The original unblended and numerically blended sections are shown in Figure \ref{fig:data1} and \ref{fig:datas}, respectively.
Figure \ref{fig:deblendedfft1,deblendedslet1,deblendedfxdecon1,difffft1,diffslet1,difffxdecon1,errorfft1,errorslet1,errorfxdecon1} shows the deblended results using soft thresholding in the $f-k$ domain, soft thresholding in the seislet domain, and $f-x$ predictive filtering. 
All of these deblending results are generally acceptable despite some artifacts left in Figure \ref{fig:deblendedfft1} and some weak-level noise left in Figure \ref{fig:deblendedfxdecon1}. By computing the difference between the deblended section and the blended section, we can obtain the blending noise section. Comparing the blending noise sections (see Figures \ref{fig:difffft1}-\ref{fig:difffxdecon1}), we find that there is some leakage of useful energy for $f-x$ predictive filtering. Computing the differences between the deblended sections and the unblended sections, we get the estimation error sections, shown in Figures \ref{fig:errorfft1}-\ref{fig:errorfxdecon1}. Compared with the other two shaping approaches, seislet-domain soft thresholding causes a nearly zero estimation error, which indicates a nearly perfect deblending result. The estimation error for $f-x$ predictive filtering is comparatively large, because of the large predictive error problem when several dipping components are taken into consideration \cite[]{yangkang2014}. The small estimation errors in Figure \ref{fig:errorfft1} are caused by spectrum mixture in the $f-k$ domain because some useful energy reside in the low amplitude part that is easy to be removed during soft thresholding. The small estimation errors shown in Figure \ref{fig:errorslet1} are caused by dip estimation error because of the conflicting dips when using plane wave destruction (PWD) algorithm with a single slope \cite[]{pwd}, which is a limitation of seislet-domain denoising approaches, unless a seislet frame is used instead of the seislet transform \cite[]{seislet}. The diagrams for convergence rates are shown in Figure \ref{fig:snrsa}, which demonstrates a superior behavior of seislet-domain soft thresholding in comparison with the other two approaches. In order to make the comparisons fair, we try to find the best deblending performance through the parameter-selection process for corresponding shaping operators. In this case, the percentages we use for $f-k$ domain and seislet domain thresholding are both 8 \%, the filter length we use for $f-x$ predictive filtering is 4 samples. 

\multiplot{2}{data1,datas}{width=0.45\textwidth,height=0.60\textwidth}{Numerically blended synthetic data (linear case). (a) Unblended data. (b) Blended data.} 
\multiplot{9}{deblendedfft1,deblendedslet1,deblendedfxdecon1,difffft1,diffslet1,difffxdecon1,errorfft1,errorslet1,errorfxdecon1}{width=0.2500\textwidth,height=0.2800\textwidth}{Deblending comparison for numerically blended synthetic data (linear case). (a) Deblended result using $f-k$ domain thresholding. (b) Deblended result using seislet-domain thresholding. (c) Deblended result using $f-x$ predictive filtering. (d) Blending noise corresponding to (a). (e) Blending noise corresponding to (b). (f) Blending noise corresponding to (c). (g) Estimation error corresponding to (a). (h) Estimation error corresponding to (b). (i) Estimation error corresponding to (c). }

\plot{snrsa}{width=0.8\textwidth}{Diagrams of SNR for synthetic example (linear case). The "+" line corresponds to seislet-domain thresholding. The "o" line corresponds to $f-k$ domain soft thresholding. The "*" line corresponds to $f-x$ predictive filtering.}

\subsection{Numerically blended synthetic data - hyperbolic events}
\inputdir{synthhyper}
Next, we create another synthetic example which contains hyperbolic events without dip conflicts. The unblended and blended data are shown in Figures \ref{fig:hyper1} and \ref{fig:hypers}, respectively. Figure \ref{fig:hyperdeblendedfft1,hyperdeblendedslet1,hyperdeblendedfxdecon1,hyperdifffft1,hyperdiffslet1,hyperdifffxdecon1,hypererrorfft1,hypererrorslet1,hypererrorfxdecon1}
shows the deblending results for the hyperbolic case. Figure \ref{fig:hypersnrsa} shows the diagrams of changing SNR for one source. In this case, the estimation error for the seislet-domain soft thresholding becomes negligible, mainly owing to the successful dip estimation when constructing the seislet transform. The strength of the $f-x$ predictive filtering also increases and its SNR diagram shows a similar behavior as the $f-k$ domain thresholding. The seislet-based shaping still outperforms the other two approaches. In this case, the percentages we use for $f-k$ domain and seislet domain thresholding are both 9 \%, the filter length we use for $f-x$ predictive filtering is 4 samples. 

\multiplot{2}{hyper1,hypers}{width=0.45\textwidth,height=0.60\textwidth}{Numerically blended synthetic data (hyperbolic case). (a) Unblended data. (b) Blended data.}

\multiplot{9}{hyperdeblendedfft1,hyperdeblendedslet1,hyperdeblendedfxdecon1,hyperdifffft1,hyperdiffslet1,hyperdifffxdecon1,hypererrorfft1,hypererrorslet1,hypererrorfxdecon1}{width=0.2500\textwidth,height=0.2800\textwidth}{Deblending comparison for numerically blended synthetic data (hyperbolic case). (a) Deblended result using $f-k$ domain thresholding. (b) Deblended result using seislet-domain thresholding. (c) Deblended result using $f-x$ predictive filtering. (d) Blending noise corresponding to (a). (e) Blending noise corresponding to (b). (f) Blending noise corresponding to (c). (g) Estimation error corresponding to (a). (h) Estimation error corresponding to (b). (i) Estimation error corresponding to (c).}

\plot{hypersnrsa}{width=0.8\textwidth}{Diagrams of SNR for synthetic example (hyperbolic case). The "+" line corresponds to seislet-domain thresholding. The "o" line corresponds to $f-k$ domain thresholding. The "*" line corresponds to $f-x$ predictive filtering.}

\subsection{Numerically blended synthetic data - complex gather}
The third synthetic dataset consists of two complex gathers, which contain both useful seismic reflections and additional components such as ground roll and coherent dipping events. We simulate this example in order to best match the field data. The unblended and blended data are shown in Figures \ref{fig:complex1} and \ref{fig:complexs}, respectively. Figure \ref{fig:complexdeblendedfft1,complexdeblendedslet1,complexdeblendedfxdecon1,complexdifffft1,complexdiffslet1,complexdifffxdecon1,complexerrorfft1,complexerrorslet1,complexerrorfxdecon1}
shows the deblending results for this case. Figure \ref{fig:complexsnrsa} shows the diagrams of changing SNR for both sources. The SNR for the converged deblended data becomes noticeably smaller compared with the previous examples for three different shaping operators respectively, which results from the fact that the seismic gather is no longer ideally sparse as the previous examples. Notice that in the noise sections for $f-k$ domain thresholding (Figure \ref{fig:complexdeblendedfft1}) and the noise sections for $f-x$ predictive filtering (Figure \ref{fig:complexdeblendedfxdecon1}), there exist a certain amount of coherent events. However, for the seislet-domain soft thresholding, there are barely any coherent events. If we look carefully at the error sections corresponding to these three shaping operators, we can find that for the $f-k$ domain thresholding, the estimation error comes from the useful hyperbolic reflections, the coherent dipping events, and the ground roll, for the $f-x$ predictive filtering, the estimation error mainly comes from the useful hyperbolic reflections and the coherent dipping events, but for the seislet-domain soft thresholding, only a small amount of the ground roll and negligible amount of coherent dipping events and deep-water horizontal reflections are left on the error sections, which is not important for the whole processing tasks. We can conclude that for complex datasets like this synthetic example, seislet-domain soft thresholding is the preferable approach for shaping regularization.
In this case, the percentages we use for $f-k$ domain and seislet domain thresholding are both 20 \%, the filter length we use for $f-x$ predictive filtering is 4 samples. 

\inputdir{synthcomplex}
\multiplot{2}{complex1,complexs}{width=0.45\textwidth,height=0.60\textwidth}{Numerically blended synthetic data (complex gather). (a) Unblended data. (b) Blended data.}

\multiplot{9}{complexdeblendedfft1,complexdeblendedslet1,complexdeblendedfxdecon1,complexdifffft1,complexdiffslet1,complexdifffxdecon1,complexerrorfft1,complexerrorslet1,complexerrorfxdecon1}{width=0.2500\textwidth,height=0.2800\textwidth}{Deblending comparison for numerically blended synthetic data (complex gather). (a) Deblended result using $f-k$ domain thresholding. (b) Deblended result using seislet-domain thresholding. (c) Deblended result using $f-x$ predictive filtering. (d) Blending noise corresponding to (a). (e) Blending noise corresponding to (b). (f) Blending noise corresponding to (c). (g) Estimation error corresponding to (a). (h) Estimation error corresponding to (b). (i) Estimation error corresponding to (c). }

\plot{complexsnrsa}{width=0.8\textwidth}{Diagrams of SNR for synthetic example (complex gather). The "+" line corresponds to seislet-domain thresholding. The "o" line corresponds to $f-k$ domain thresholding. The "*" line corresponds to $f-x$ predictive filtering.}

\subsection{Numerically blended field data }

Finally, we use a field data example to further test the effectiveness for our proposed algorithm. The field data is similar in appearance to the previous synthetic example. Because of the previous test, we only used seislet-domain soft thresholding as the shaping operator.
The two blended data are shown in Figures \ref{fig:blended763} and \ref{fig:blended754} and appear noisy.
 After 30 iterations of seislet-domain soft thresholding, the deblending results are shown in Figures \ref{fig:shotdeblendedslet1} and \ref{fig:shotdeblendedslet2}.  The intense interference in the shallow part has been removed to a large extent. The deep-water reflection becomes much clearer because of a significant drop in the noise energy for the whole profile. From the noise sections, we can observe only a small amount of ground roll, which is analogous to the results of the previous synthetic test, and a even less amount of direct waves and shallow part horizontal reflections, which is not significant. The $SNR$ defined in equation \ref{eq:diff} obtained an increase from 1.00 $dB$ to 5.50 $dB$ for the first source and from 0.83 $dB$ to 5.50 $dB$ for the second source. The error sections for this field data test are not given since the unblended data for this test contain much random noise, which can not be estimated.
However, from the point of view of random noise attenuation, which is concerned with the signal content of the denoised section and the randomness of the noise section, the deblending result of the field data test is acceptable. In this case, the percentage we use for seislet domain thresholding is 18\%.

The main computational cost of the proposed approach lays on the forward and inverse seislet transforms. As analyzed by \cite{seislet}, the seislet transform has linear $O(N)$ cost. It can be more expensive than fast Fourier transform and digital wavelet transform, but is still comfortably efficient in practice. Considering that for the 2D seislet transform, the main cost may not be in the transform itself but in the iterative estimation of the slope fields, we update slope estimation every several iterations (e.g., every 5 iterations in this field data example) to reduce the computational cost.

\inputdir{fairfield-initmfnew}
\multiplot{6}{blended763,blended754,shotdeblendedslet2,shotdeblendedslet1,shotdiffslet2,shotdiffslet1}{width=0.42\textwidth,height=0.3600\textwidth}{Deblending comparison for the real data. (a) Blended source 1. (b) Blended source 2. (c) Deblended source 1. (d) Deblended source 2. (e) Blending noise for source 1. (f) Blending noise for source 2.}

\section{Conclusions}
We have proposed a novel iterative framework, which offers a flexible way to control deblending using sparsity or coherency constraints.  
When the seismic data are relatively clean and do not contain much coherent noise, $f-k$ domain sparsity-promoting operator or $f-x$ predictive filtering might be adequate to handle the blending noise. However, when the blended data become more complicated, a more robust sparsity or coherency-promoting tool should be utilized. The seislet transform has an inherent ability to compress coherent seismic data, because it is generated based on predictability between neighboring traces using the local slope information. As long as we can get an acceptable slope estimation, the seislet-transformed data appears sparse.
Our experiments indicate that it is possible to get accurate results within a small number of iterations when an appropriate shaping operator is taken. 

\section{Acknowledgments}
We thank FairfieldNodal for providing the field data used in this study. We thank Alexander Klokov, Karl Schleicher, Parvaneh Karimi, Araz Mahdad, Josef Paffenholz, David Hays, Paul Docherty and Le-wei Mo for helpful discussions. We also thank Sam Kaplan, Chengbo Li, Jinkun Cheng, Jeff Shragge, Evert Slob, and one anonymous reviewer for their constructive suggestions, which helped improve this paper. 

\newpage
\onecolumn
\bibliographystyle{seg}
\bibliography{simul}
\newpage
\append{Review of seislet transform}
\cite{fomel4} and \cite{seislet} proposed a digital wavelet-like transform, which is defined with the help of the wavelet-lifting scheme \cite[]{lifting} combined with local plane-wave destruction. The wavelet-lifting utilizes predictability of even traces from odd traces of 2-D seismic data and finds a difference $\mathbf{r}$ between them, which can be expressed as:
\begin{equation}
\label{eq:one}
\mathbf{r}=\mathbf{o}-\mathbf{P\left[e\right]},
\end{equation}
where $\mathbf{P}$ is the prediction operator.
A coarse approximation $\mathbf{c}$ of the data can be achieved by updating the even component:
\begin{equation}
\label{eq:two}
\mathbf{c}=\mathbf{e}+\mathbf{U\left[r\right]},
\end{equation}
where $\mathbf{U}$ is the updating operator.

The digital wavelet transform can be inverted by reversing the lifting-scheme operations as follows:
\begin{equation}
\label{eq:three}
\mathbf{e}=\mathbf{c}-\mathbf{U\left[r\right]},
\end{equation}
\begin{equation}
\label{eq:four}
\mathbf{o}=\mathbf{r}+\mathbf{P\left[e\right]}.
\end{equation}

The foward transform starts with the finest scale (the original sampling) and goes to the coarsest scale. The inverse transfrom starts with the coarsest scale and goes back to the finest scale. At the start of forward transform, $\mathbf{e}$ and $\mathbf{o}$ corresponds to the even and odd traces of the data domain. At the start of the inverse transform, $\mathbf{c}$ and $\mathbf{r}$ will have just one trace of the coarsest scale of the seislet domain.

The above prediction and update operators can be defined, for example, as follows:
\begin{equation}
\label{eq:five}
\mathbf{P}\left[\mathbf{e}\right]_k=\left(\mathbf{P}^{(+)}_k\left[\mathbf{e}_{k-1}\right]+\mathbf{P}^{(-)}_k\left[\mathbf{e}_k\right]\right)/2,
\end{equation}
and
\begin{equation}
\label{eq:six}
\mathbf{U}\left[\mathbf{r}\right]_k=\left(\mathbf{P}^{(+)}_k\left[\mathbf{r}_{k-1}\right]+\mathbf{P}^{(-)}_k\left[\mathbf{r}_k\right]\right)/4,
\end{equation}
where $\mathbf{P}^{(+)}_k$ and $\mathbf{P}^{(-)}_k$ are operators that predict a trace from its left and right neighbors, correspondingly, by shifting seismic events according to their local slopes. 
This scheme is analogous to CDF biorthogonal wavelets \cite[]{cohen1992}. The predictions need to operate at different scales, which means different separation distances between traces. Taken through different scales, equations \ref{eq:one}-\ref{eq:six} provide a simple definition for the 2D seislet transform.  More accurate versions are based on other schemes for the digital wavelet transform \cite[]{liuyang20091}.
